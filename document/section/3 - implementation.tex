\section{Implementazione}
\label{impl}
\subsection{Knowledge Base (KB)}
La Knowledge Base in NELL è una re-implementazione di THEO basata su Tokyo Cabinet. La Knowledge Base riesce a gestire milioni di valori su una singola macchina mantenendo le performance costanti prima di aver necessità di scalare\cite{TowardAnArchitecture:online}.
\subsubsection{THEO}
THEO è un framework nato per imparare a risolvere problemi. 
\paragraph{Principi}
I principi architetturali di THEO possono essere raccolti su due livelli, funzionale e strutturale. Si possono vedere questi principi anche come dei requisiti che la struttura deve possedere.

\noindent In termini funzionali l'architettura deve permettere una vasta gamma di possibili rappresentazioni, massimizzando:
\begin{itemize}
	\item la gamma delle credenze rappresentabili;
	\item la gamma delle domande che è possibile formulare date le credenze;
	\item la gamma delle inferenze che possono essere rappresentate;
	\item la gamma di conoscenze che è possibile apprendere;
\end{itemize}

In termini strutturali, i dati devono essere strutturati in modo preciso e seguire le convenzioni prestabilite, in modo da poter rendere possibili meccanismi come l'inferenza, l'apprendimento, il recupero di una certa informazione data un'interrogazione etc.

\paragraph{Organizzazione}
Seguono i principi organizzativi per quanto riguarda la strutturazione dei dati i THEO:

\begin{itemize}
	\item Ogni credenza è un'asserzione nella forma $(<entity><slot>) = <value>$. Questa asserzione indica il fatto che una certa entità denominata $<entity>$ ha un certo tipo di relazione denominata $<slot>$ con un'altra entità denominata $<value>$. Un esempio di istanza è per esempio $({\textrm{fred}\;\textrm{wife}) = \textrm{velma}}$.
	\item Ogni istanza di un problema in THEO è una coppia nella forma $<entity> <slot>$. Questa coppia rappresenta un task per cui è possibile trovare soluzioni nella forma $(<entity><slot>) = <value>$. Per esempio ponendo il problema $(\textrm{fred}\;\textrm{wife})$ una possibile soluzione è appunto la tripla descritta al punto precedente, dove $<value>$ è velma.
	\begin{info}
		Questo meccanismo è praticamente lo stesso della programmazione logica. Prendendo per esempio come linguaggio di riferimento Prolog è possibile memorizzare i fatti di interesse come segue:
		\begin{code}
			\captionof{listing}{Credenze THEO espresse in Prolog}
			\begin{minted}{prolog}
fred.
velma.
wife(fred, velma).
			\end{minted}
		\end{code}
Ed è possibile esprimere l'interrogazione nel seguente modo:
		\begin{code}
	\captionof{listing}{Credenze THEO espresse in Prolog}
	\begin{minted}{prolog}
wife(fred, X). % 1 solution -> X = velma [wife(fred, velma)]
	\end{minted}
\end{code}
In questo caso troviamo tutte le entità legate dalla relazione wife a fred.
	\end{info} 
\item Classi di problemi possono essere descritti in due modi differenti:
\begin{itemize}
	\item da un singolo token $<slot>$. In questo caso sono rappresentati tutti i problemi nella forma $(?x\;<slot>)$ dove $?x$ è un qualsiasi membro del dominio $<slot>$. Se per esempio $(\textrm{slot}\; \textrm{domain}) = \textrm{male}$ allora $?x$ può essere una qualunque entità con dominio "male".
	\item da una coppia del tipo $(<entity><slot>)$. In questo caso ci troviamo in un sottoinsieme del caso precedente, in cui viene specificato il dominio di $<entity>$.
\end{itemize}
\item Istanze di problemi e classi di problemi sono a loro volta entità. THEO in questo modo può avere credenze riguardo problemi, e permettere di porvi problemi sopra. Per esempio, nella seguente asserzione  $((\textrm{fred}\; \textrm{wife}) \textrm{difficult?}) = \textrm{no}$, "$(\textrm{fred}\; \textrm{wife})$" è $<entity>$, "$\textrm{difficult?}$" è $<slot>$ mentre "$\textrm{no}$" è $<value>$. In questo caso siamo riusciti a descrivere un problema, specificando che trovare una soluzione non è difficile.
\item THEO memorizza tutta la conoscenza riguardante potenziali metodi per la risoluzione di problemi come delle credenze riguardanti la specifica classe di problemi. Per esempio, l'asserzione $((\textrm{fred}\;\textrm{wife}) available.mathods) = (\textrm{inherits}\;\textrm{default.value)}$ specifica che i metodi disponibili per risolvere il problema "$(\textrm{fred}\; \textrm{wife})$" sono "$\textrm{inherits}$" e $\textrm{default.value}$.
\item Una volta che un problema viene risolto, THEO può memorizzare la soluzione indicizzata utilizzando il nome del problema stesso. Quando la credenza viene aggiunta viene anche memorizzata una spiegazione che giustifica la nuova asserzione in termini delle credenze da cui dipende. THEO è in grado di rimuovere le credenze che sono dipendenti da altre credenze che vengono eliminate o modificate, in modo da mantenere consistente la base di dati\cite{theofram80:online}.
\end{itemize}
\subsubsection{Tokyo Cabinet}

\begin{warn}
	Tokyo Cabinet è ormai abbastanza datata. Nel frattempo è stata distributa Tkrzw, una libreria nata dallo stesso progetto ma che ha superato Tokyo Cabinet sotto ogni aspetto, rendendola ormai una tecnologia deprecata.
\end{warn}

\noindent Tokyo Cabinet è una libreria per la gestione di database. Il sistema è basato su file contenente dei record. Un record è di fatto una coppia chiave-valore. La dimensione delle chiavi e dei valori è variabile. Non ci sono vincoli di tipizzazione nè per le chiavi nè per i valori. Non esiste di fatto il concetto di tabelle e nemmeno quello dei tipi di dato. I record sono organizzati tramite l'utilizzo di tabelle Hash, B+ tree o array di dimensione statica.

\centeredImage{img/tokyo\_cabinet\_logo.png}{Logo di Tokyo Cabinet\cite{TokyoCab61:online}}{0.2}

\noindent Tokyo Cabinet è stata sviluppato come successore di GDBM and QDBM con il fine di apportare i migliramenti che vengono ora elencati:
\begin{itemize}
	\item \textbf{migliorare l'efficienza nell'utilizzo dello spazio}: file più piccoli permettono una maggior capacità di memorizzazione;
	\item \textbf{migliorare l'efficienza del tempo}: più velocità nel recupero e nella scrittura dei dati;
	\item \textbf{miglioramento del parallelismo}: performance più elevate in ambienti che permettono il multi-threading;
	\item \textbf{miglioramento dell'usabilità}: grazie ad API più semplici;
	\item \textbf{miglioramento della robustezza}: meccanismi di protezione che impediscono la corruzione di un file, anche in caso di situazioni catastrofiche;
	\item \textbf{supporto all'architettura a 64 bit}: permette maggiore spazio e velocità, quindi un incremento delle performance generali.
\end{itemize}

\noindent Tokyo Cabinet è scritto in C e fornisce API per i linguaggi C, Perl, Ruby, Java e Lua.
La libreria può essere utilizzata in un qualsiasi ambiente conforme all'utilizzo di C99 e POSIX. Tokyo Cabinet è un software gratuito, licenziato sotto la GNU Lesser General Public License\cite{TokyoCab61:online}.
\subsection{Subsystem Components}
I quattro componenti utilizzati da NELL hanno tutti come obiettivo comune l'identificazione di nuovi fatti candidati. Ogni componente però utilizza tecniche differenti. In questo modo è possibile aumentare l'accuratezza dei risultati. I Subsystem Components sono:
\subsubsection{Coupled Pattern Learner (CPL)}
Si tratta di un componente che si occupa di estrazione del testo, utilizzando pattern testuali come "maggiore di X" o "X gioca in Y" per estrarre istanze di categorie e relazioni. Utilizza un algoritmo di Machine Learning che accoppia il learning semi-supervisionato di categorie e relazioni. Approcci più tradizionali non riescono a classificare in modo efficace i dati quando la differenza di cardinalità tra dati etichettati e non etichettati è elevata.

\noindent CPL utilizza statistiche di occorrenza tra i sostantivi e alcuni pattern (grazie al PoS tagging) per imparare pattern di estrazione per ogni predicato di interesse. Vengono poi utilizzati gli stessi pattern per trovare nuovi predicati.
Anche l'utilizzo di relazioni tra i predicati vengono utilizzate per una migliore valutazione complessiva.

\noindent Le probabilità di ogni fatto candidato estratto da questo componente vengono calcolate utilizzando la formula $1 - 0.5^{c}$ dove $c$ è il numero di pattern che hanno estratto il candidato\cite{TowardAnArchitecture:online}.
\begin{info}[PoS tagging]
	Il Part of Speech Tagging, anche chiamato tagging grammaticale, è il processo di marcatura ed etichettatura di una parola in un testo come corrispondente a una parte particolare del discorso, basata sia sulla sua definizione che sul suo contesto\cite{POStagsa85:online}.
\end{info}

\begin{code}
\captionof{listing}{Descrizione dell'algoritmo CPL \cite{Coupledp1:online}}
\begin{minted}{java}
// Input: An ontology O, and a text corpus C 
// Output: Trusted instances/patterns for each predicate
while(true) {
	for(Predicate p : Ontology o) {
		/*
		1) EXTRACT candidate instances/contextual patterns 
		using recently promoted patterns/instances;
		2) FILTER candidates that violate coupling;
		3) RANK candidate instances/patterns;
		4) PROMOTE top candidates;
		*/
	}
}
\end{minted}
\end{code}

\subsubsection{Coupled SEAL (CSEAL)}
Si tratta di un componente che interroga Internet avendo a disposizione come punto di partenza  un insieme di credenze. Per ogni categoria o relazione di interesse, CSEAL crea strutture dati (liste e tabelle) da cui estrapola informazioni per trovare nuove istanze del predicato corrispondente. CSEAL è stato configurato per eseguire 5 query per ogni categoria e 10 query per ogni relazione, utilizzando 50 pagine web diverse per ogni query.
Le probabilità di ogni fatto candidato estratto da questo componente vengono calcolate utilizzando la stessa formula di CPL dove $c$ è il numero di "wrapper" che hanno individuato l'istanza \cite{TowardAnArchitecture:online}.
\subsubsection{Coupled Morphological Classifier (CMC)}
Si tratta di un componente composto da un insieme di modelli di regressione logistica con regolarizzazione $L_{2}$ (uno per categoria). In questo caso i sostantivi vengono classificati grazie a feature morfologiche (struttura delle parole, presenza di lettere maiuscole e minuscole, PoS etc.). Le credenze della KB vengono utilizzate come istanze di training, ma ad ogni iterazione CMC utilizza solo predicati che hanno almeno 100 istanze che sono state promosse.
CMC esamina anche fatti candidati proposti dagli altri componenti, e riesce a classificare sempre almeno 30 nuove credenze per predicato ogni iterazione\cite{TowardAnArchitecture:online}.
\begin{info}[Regressione logistica]
Si tratta di un modello di regressione dove la variabile dipendente è dicotomica, ossia una variabile che può avere come unici valori 0 e 1 o riconducibili ad essi. Sostanzialmente il modello calcola la probabilità che questa variabile acquisisca valore 1 \cite{Modellol35:online}.
\end{info}
\centeredImage{img/logistic.png}{Esempio di funzione del modello logistico \cite{Modellol35:online}}{0.2}

\begin{info}[Regolarizzazione L2]
	Il problema che si vuole risolvere è quello dell'overfitting.\newline Anche chiamata Ridge Regression, la regolarizzazione L2 è analoga alla L1, con la differenza che si utilizza la somma dei quadrati dei pesi, invece della sola somma \cite{DeepLear11:online}.
\end{info}

\subsubsection{Rule Learner (RL)}
Un algoritmo di apprendimento relazionale di primo ordine molto simile a FOIL. Lo scopo dell'algoritmo è imparare regole che vengono poi utilizzate per acquisire tramite inferenza nuove istanze di relazioni a partire da quelle già presenti nella Knowledge Base.
\begin{info}[FOIL]
	Un sistema di apprendimento di primo ordine che usa informazioni organizzate in una collezione di relazioni per costruire teorie espresse attraverso il linguaggio logico Prolog\cite{Inductio61:online}.
\end{info}

\subsection{Knowledge Integrator (KI)}
L'implementazione del Knowledge Integrator è molto semplice. Il componente promuove i fatti candidati a credenza in base alla probabilità che il fatto sia accurato. Questo valore è fornito direttamente dai Subsystem Component. Il KI non ha quindi bisogno di ulteriore computazione per estrapolare i valori.
I fatti candidati vengono promossi a credenze se:
\begin{itemize}
	\item una singola sorgente propone un fatto che supera un certo livello di confidenza hardcoded (probabilità a posteriori $> 0.9$).
	\item più sorgenti propongono lo stesso fatto anche se non superano il livello di confidenza necessario per le fonti singole.
\end{itemize}
Il KI sfrutta le relazioni tra i predicati e rispetta le informazioni relative alla mutua esclusione ed al type checking. Per esempio categorie candidate non vengono promosse se ci sono conflitti particolari con altre istanze già presenti all'interno della KB.
Le relazioni candidate non vengono promosse se alcuni vincoli di categoria degli argomenti non vengono rispettati.

\noindent Nell'implementazione corrente, una volta che un fatto candidato viene promosso a credenza, non può essere declassato. Il KI è configurato per promuovere fino a 250 istanza per ogni predicato in ogni iterazione, ma raramente questa soglia è stata raggiunta.
\newpage