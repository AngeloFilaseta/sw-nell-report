\section{Implementazione}
\label{impl}
\subsection{Knowledge Base (KB)}
La Knowledge Base in NELL è una re-implementazione di THEO basata su Tokyo Cabinet. La Knowledge Base riesce a gestire milioni di valori su una singola macchina mantenendo le performance costanti prima di aver necessità di scalare\cite{TowardAnArchitecture:online}.
\subsubsection{THEO}
\cite{theofram80:online}
\subsubsection{Tokyo Cabinet}

\begin{warn}
	Tokyo Cabinet è ormai abbastanza datata. Nel frattempo è stata distributa Tkrzw, una libreria nata dallo stesso progetto ma che ha superato Tokyo Cabinet sotto ogni aspetto, rendendola ormai una tecnologia deprecata.
\end{warn}

\noindent Tokyo Cabinet è una libreria per la gestione di database. Il sistema è basato su file contenente dei record. Un record è di fatto una coppia chiave-valore. La dimensione delle chiavi e dei valori è variabile. Non ci sono vincoli di tipizzazione nè per le chiavi nè per i valori. Non esiste di fatto il concetto di tabelle e nemmeno quello dei tipi di dato. I record sono organizzati tramite l'utilizzo di tabelle Hash, B+ tree o array di dimensione statica.

\centeredImage{img/tokyo\_cabinet\_logo.png}{Logo di Tokyo Cabinet\cite{TokyoCab61:online}}{0.2}

\noindent Tokyo Cabinet è stata sviluppato come successore di GDBM and QDBM con il fine di apportare i migliramenti che vengono ora elencati:
\begin{itemize}
	\item \textbf{migliorare l'efficienza nell'utilizzo dello spazio}: file più piccoli permettono una maggior capacità di memorizzazione;
	\item \textbf{migliorare l'efficienza del tempo}: più velocità nel recupero e nella scrittura dei dati;
	\item \textbf{miglioramento del parallelismo}: performance più elevate in ambienti che permettono il multi-threading;
	\item \textbf{miglioramento dell'usabilità}: grazie ad API più semplici;
	\item \textbf{miglioramento della robustezza}: meccanismi di protezione che impediscono la corruzione di un file, anche in caso di situazioni catastrofiche;
	\item \textbf{supporto all'architettura a 64 bit}: permette maggiore spazio e velocità, quindi un incremento delle performance generali.
\end{itemize}

\noindent Tokyo Cabinet è scritto in C e fornisce API per i linguaggi C, Perl, Ruby, Java e Lua.
La libreria può essere utilizzata in un qualsiasi ambiente conforme all'utilizzo di C99 e POSIX. Tokyo Cabinet è un software gratuito, licenziato sotto la GNU Lesser General Public License\cite{TokyoCab61:online}.
\subsection{Subsystem Components}
I quattro componenti utilizzati da NELL hanno tutti come obiettivo comune l'identificazione di nuovi fatti candidati. Ogni componente però utilizza tecniche differenti. In questo modo è possibile aumentare l'accuratezza dei risultati. I Subsystem Components sono:
\subsubsection{Coupled Pattern Learner (CPL)}
Si tratta di un componente che si occupa di estrazione del testo, utilizzando pattern testuali come "maggiore di X" o "X gioca in Y" per estrarre istanze di categorie e relazioni. Utilizza un algoritmo di Machine Learning che accoppia il learning semi-supervisionato di categorie e relazioni. Approcci più tradizionali non riescono a classificare in modo efficace i dati quando la differenza di cardinalità tra dati etichettati e non etichettati è elevata.

\noindent CPL utilizza statistiche di occorrenza tra i sostantivi e alcuni pattern (grazie al PoS tagging) per imparare pattern di estrazione per ogni predicato di interesse. Vengono poi utilizzati gli stessi pattern per trovare nuovi predicati.
Anche l'utilizzo di relazioni tra i predicati vengono utilizzate per una migliore valutazione complessiva.

\noindent Le probabilità di ogni fatto candidato estratto da questo componente vengono calcolate utilizzando la formula $1 - 0.5^{c}$ dove $c$ è il numero di pattern che hanno estratto il candidato\cite{TowardAnArchitecture:online}.
\begin{info}[PoS tagging]
	Il Part of Speech Tagging, anche chiamato tagging grammaticale, è il processo di marcatura ed etichettatura di una parola in un testo come corrispondente a una parte particolare del discorso, basata sia sulla sua definizione che sul suo contesto\cite{POStagsa85:online}.
\end{info}

\begin{code}
\captionof{listing}{Descrizione dell'algoritmo CPL \cite{Coupledp1:online}}
\begin{minted}{java}
// Input: An ontology O, and a text corpus C 
// Output: Trusted instances/patterns for each predicate
while(true) {
	for(Predicate p : Ontology o) {
		/*
		1) EXTRACT candidate instances/contextual patterns 
		using recently promoted patterns/instances;
		2) FILTER candidates that violate coupling;
		3) RANK candidate instances/patterns;
		4) PROMOTE top candidates;
		*/
	}
}
\end{minted}
\end{code}

\subsubsection{Coupled SEAL (CSEAL)}
Si tratta di un componente che interroga Internet avendo a disposizione come punto di partenza  un insieme di credenze. Per ogni categoria o relazione di interesse, CSEAL crea strutture dati (liste e tabelle) da cui estrapola informazioni per trovare nuove istanze del predicato corrispondente. CSEAL è stato configurato per eseguire 5 query per ogni categoria e 10 query per ogni relazione, utilizzando 50 pagine web diverse per ogni query.
Le probabilità di ogni fatto candidato estratto da questo componente vengono calcolate utilizzando la stessa formula di CPL dove $c$ è il numero di "wrapper" che hanno individuato l'istanza \cite{TowardAnArchitecture:online}.
\subsubsection{Coupled Morphological Classifier (CMC)}
Si tratta di un componente composto da un insieme di modelli di regressione logistica con regolarizzazione $L_{2}$ (uno per categoria). In questo caso i sostantivi vengono classificati grazie a feature morfologiche (struttura delle parole, presenza di lettere maiuscole e minuscole, PoS etc.). Le credenze della KB vengono utilizzate come istanze di training, ma ad ogni iterazione CMC utilizza solo predicati che hanno almeno 100 istanze che sono state promosse.
CMC esamina anche fatti candidati proposti dagli altri componenti, e riesce a classificare sempre almeno 30 nuove credenze per predicato ogni iterazione\cite{TowardAnArchitecture:online}.
\begin{info}[Regressione logistica]
Si tratta di un modello di regressione dove la variabile dipendente è dicotomica, ossia una variabile che può avere come unici valori 0 e 1 o riconducibili ad essi. Sostanzialmente il modello calcola la probabilità che questa variabile acquisisca valore 1 \cite{Modellol35:online}.
\end{info}
\centeredImage{img/logistic.png}{Esempio di funzione del modello logistico \cite{Modellol35:online}}{0.2}

\begin{info}[Regolarizzazione L2]
	Il problema che si vuole risolvere è quello dell'overfitting.\newline Anche chiamata Ridge Regression, la regolarizzazione L2 è analoga alla L1, con la differenza che si utilizza la somma dei quadrati dei pesi, invece della sola somma \cite{DeepLear11:online}.
\end{info}

\subsubsection{Rule Learner (RL)}
Un algoritmo di apprendimento relazionale di primo ordine molto simile a FOIL. Lo scopo dell'algoritmo è imparare regole che vengono poi utilizzate per acquisire tramite inferenza nuove istanze di relazioni a partire da quelle già presenti nella Knowledge Base.
\begin{info}[FOIL]
	Un sistema di apprendimento di primo ordine che usa informazioni organizzate in una collezione di relazioni per costruire teorie espresse attraverso il linguaggio logico Prolog\cite{Inductio61:online}.
\end{info}

\subsection{Knowledge Integrator (KI)}
L'implementazione del Knowledge Integrator è molto semplice. Il componente promuove i fatti candidati a credenza in base alla probabilità che il fatto sia accurato. Questo valore è fornito direttamente dai Subsystem Component. Il KI non ha quindi bisogno di ulteriore computazione per estrapolare i valori.
I fatti candidati vengono promossi a credenze se:
\begin{itemize}
	\item una singola sorgente propone un fatto che supera un certo livello di confidenza hardcoded (probabilità a posteriori $> 0.9$).
	\item più sorgenti propongono lo stesso fatto anche se non superano il livello di confidenza necessario per le fonti singole.
\end{itemize}
Il KI sfrutta le relazioni tra i predicati e rispetta le informazioni relative alla mutua esclusione ed al type checking. Per esempio categorie candidate non vengono promosse se ci sono conflitti particolari con altre istanze già presenti all'interno della KB.
Le relazioni candidate non vengono promosse se alcuni vincoli di categoria degli argomenti non vengono rispettati.

\noindent Nell'implementazione corrente, una volta che un fatto candidato viene promosso a credenza, non può essere declassato. Il KI è configurato per promuovere fino a 250 istanza per ogni predicato in ogni iterazione, ma raramente questa soglia è stata raggiunta.
\newpage