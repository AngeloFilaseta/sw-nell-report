\section{Implementazione}
\label{impl}
\subsection{Subsystem Components}
I quattro componenti utilizzati da NELL hanno tutti come obiettivo comune l'identificazione di nuovi fatti candidati. Ogni componente però utilizza tecniche differenti. In questo modo è possibile aumentare l'accuratezza dei risultati. I Subsystem Components sono:
\subsubsection{Coupled Pattern Learner (CPL)}
Si tratta di un componente che si occupa di estrazione del testo, utilizzando pattern testuali come "maggiore di X" o "X gioca in Y" per estrarre istanze di categorie e relazioni. Utilizza un algoritmo di Machine Learning che accoppia il learning semi-supervisionato di categorie e relazioni. Approcci più tradizionali non riescono a classificare in modo efficace i dati quando la differenza di cardinalità tra dati etichettati e non etichettati è elevata.

\noindent CPL utilizza statistiche di occorrenza tra i sostantivi e alcuni pattern (grazie al PoS tagging) per imparare pattern di estrazione per ogni predicato di interesse. Vengono poi utilizzati gli stessi pattern per trovare nuovi predicati.
Anche l'utilizzo di relazioni tra i predicati vengono utilizzate per una migliore valutazione complessiva.

\noindent Le probabilità di ogni fatto candidato estratto da questo componente vengono calcolate utilizzando la formula $1 - 0.5^{c}$ dove $c$ è il numero di pattern che hanno estratto il candidato\cite{TowardAnArchitecture:online}.
\begin{info}[PoS tagging]
	Il Part of Speech Tagging, anche chiamato tagging grammaticale, è il processo di marcatura ed etichettatura di una parola in un testo come corrispondente a una parte particolare del discorso, basata sia sulla sua definizione che sul suo contesto\cite{POStagsa85:online}.
\end{info}

\begin{code}
\captionof{listing}{Descrizione dell'algoritmo CPL \cite{Coupledp1:online}}
\begin{minted}{java}
// Input: An ontology O, and a text corpus C 
// Output: Trusted instances/patterns for each predicate
while(true) {
	for(Predicate p : Ontology o) {
		/*
		1) EXTRACT candidate instances/contextual patterns 
		using recently promoted patterns/instances;
		2) FILTER candidates that violate coupling;
		3) RANK candidate instances/patterns;
		4) PROMOTE top candidates;
		*/
	}
}
\end{minted}
\end{code}


\subsubsection{Coupled SEAL (CSEAL)}
Si tratta di un componente che interroga Internet avendo a disposizione come punto di partenza  un insieme di credenze. Per ogni categoria o relazione di interesse, CSEAL crea strutture dati (liste e tabelle) da cui estrapola informazioni per trovare nuove istanze del predicato corrispondente. CSEAL è stato configurato per eseguire 5 query per ogni categoria e 10 query per ogni relazione, utilizzando 50 pagine web diverse per ogni query.
Le probabilità di ogni fatto candidato estratto da questo componente vengono calcolate utilizzando la stessa formula di CPL dove $c$ è il numero di "wrapper" che hanno individuato l'istanza \cite{TowardAnArchitecture:online}.
\subsubsection{Coupled Morphological Classifier (CMC)}
Si tratta di un componente composto da un insieme di modelli di regressione logistica con regolarizzazione $L_{2}$ (uno per categoria). In questo caso i sostantivi vengono classificati grazie a feature morfologiche (struttura delle parole, presenza di lettere maiuscole e minuscole, PoS etc.). Le credenze della KB vengono utilizzate come istanze di training, ma ad ogni iterazione CMC utilizza solo predicati che hanno almeno 100 istanze che sono state promosse.
CMC esamina anche fatti candidati proposti dagli altri componenti, e riesce a classificare sempre almeno 30 nuove credenze per predicato ogni iterazione\cite{TowardAnArchitecture:online}.
\begin{info}[Regressione logistica]
Si tratta di un modello di regressione dove la variabile dipendente è dicotomica, ossia una variabile che può avere come unici valori 0 e 1 o riconducibili ad essi. Sostanzialmente il modello calcola la probabilità che questa variabile acquisisca valore 1 \cite{Modellol35:online}.
\end{info}
\centeredImage{img/logistic.png}{Esempio di funzione del modello logistico \cite{Modellol35:online}}{0.2}

\begin{info}[Regolarizzazione L2]
	Il problema che si vuole risolvere è quello dell'overfitting.\newline Anche chiamata Ridge Regression, la regolarizzazione L2 è analoga alla L1, con la differenza che si utilizza la somma dei quadrati dei pesi, invece della sola somma \cite{DeepLear11:online}.
\end{info}

\subsubsection{Rule Learner (RL)}
Un algoritmo di apprendimento relazionale di primo ordine molto simile a FOIL. Lo scopo dell'algoritmo è imparare regole che vengono poi utilizzate per acquisire tramite inferenza nuove istanze di relazioni a partire da quelle già presenti nella Knowledge Base.
\begin{info}[FOIL]
	Un sistema di apprendimento di primo ordine che usa informazioni organizzate in una collezione di relazioni per costruire teorie espresse attraverso il linguaggio logico Prolog\cite{Inductio61:online}.
\end{info}

\subsection{Knowledge Integrator (KI)}
L'implementazione del Knowledge Integrator è molto semplice. Il componente promuove i fatti candidati a credenza in base alla probabilità che il fatto sia accurato. Questo valore è fornito direttamente dai Subsystem Component. Il KI non ha quindi bisogno di ulteriore computazione per estrapolare i valori.
I fatti candidati vengono promossi a credenze se:
\begin{itemize}
	\item una singola sorgente propone un fatto che supera un certo livello di confidenza hardcoded (probabilità a posteriori $> 0.9$).
	\item più sorgenti propongono lo stesso fatto anche se non superano il livello di confidenza necessario per le fonti singole.
\end{itemize}
Il KI sgrutta le relazioni tra i predicati e rispetta le informazioni relative alla mutua esclusione ed al type checking. Per esempio categorie candidate non vengono promosse se ci sono conflitti particolari con altre istanze già presenti all'interno della KB.
Le relazioni candidate non vengono promosse se alcuni vincoli di categoria degli argomenti non vengono rispettati.

\noindent Nell'implementazione corrente, una volta che un fatto candidato viene promosso a credenza, non può essere declassato. Il KI è configurato per promuovere fino a 250 istanza per ogni predicato in ogni iterazione, ma raramente questa soglia è stata raggiunta.
\newpage