\section{Design}
\subsection{Approcio ad alto livello}

I dati che sono stati forniti a NELL alla sua prima computazione sono stati i seguenti:
\begin{itemize}
    \item un'ontologia, contenente circa qualche centinaio di categorie(tra cui \textit{persone}, \textit{team sportivi}, \textit{frutta}, \textit{emozioni}) e di relazioni(\textit{giocaNelTeam(atleta, team)}, \textit{suonaStrumento(musicista, strumentoMusicale)};
    \item circa 10 o 15 esempi di seed per ogni categoria o relazione (per esempio una dozzina di istanze di città, fiori, etc.);
    \item una collezione di circa 500 milioni di pagine web da cui estrapolare le informazioni;
    \begin{info}
        Anche se vengono fornite web in input, parte dell'algoritmo di NELL contiene anche indicazioni su come raggiungerne autonomamente altre.
    \end{info}
\end{itemize}

\noindent Dal 2010 NELL continua la sua computazione, 24 ore su 24, senza mai fermarsi, eseguendo a ripetizione due macro task:
\begin{enumerate}
    \item \textbf{estrazione di nuove istanze di categorie o relazioni}: in altre parole si cercano nuovi sostantivi (\textit{noun phrases} è il termine tecnico utilizzato per indicare soggetti composti) che possano essere legati ad una categoria già presente(es: \textit{"Barack Obama"} è sia una \textbf{persona} che un \textbf{politico}) o due nuovi sostantivi legati da una relazione già presente (es: \textit{"Taylor Swift"} \textbf{si è esibita} al \textit{"Levi's Stadium"}). Questi fatti vengono quindi aggiunti alla knowledge base e prendono il nome di "fatti candidati".
    \item \textbf{impara a leggere meglio di ieri}: NELL utilizza diversi metodi per estrarre informazioni dal web. Tutti gli algoritmi utilizzati subiscono un processo di training continuo utilizzando anche i nuovi dati trovati. Il metodo di apprendimento utilizzato da NELL è semi-supervisionato. Il suo successo è dovuto principalmente al continuo addestramento sui dati da parte di tutti gli algoritmi utilizzati per identificare fatti\cite{ReadtheWebOverview:online}.
\end{enumerate}

\begin{info}[Training semi-supervisionato]
	Si tratta di un approccio del Machine Learning che combina una piccola quantità di dati etichettati ed una grossa quantità di dati non etichettati durante il processo di training.
	L'utilizzo di entrambi i tipi di dati può aumentare in modo considerevole l'accuratezza complessiva. L'acquisizione di dati etichettati è però spesso impossibile senza l'ausilio di una risorsa umana.
\end{info}

\subsection{Architettura}
L'Architettura di NELL si basa su una knowledge base condivisa ed utilizzata da diversi componenti denominati \textit{Subsystem Components} che vi effettuano sopra operazioni di lettura e scrittura. 

\noindent I componenti presenti sono i seguenti:
\begin{itemize}
    \item \textbf{Knowledge Base(KB)}: la base di dati condivisa in cui i fatti di interesse possono essere di due tipi:
    \begin{itemize}
        \item \textbf{Fatti candidati (Candidate Facts)}: Un fatto che si ritiene possa essere vero, ma che non è ancora stato classificato come credenza.
        \item \textbf{Credenze (Beliefs)}: Un fatto che viene considerato corretto a fronte di una decisione da parte del Knowledge Integrator.
    \end{itemize}
    \item \textbf{Subsystem Components}: i componenti che possono leggere dalla knowledge base e consultare altre risorse esterne per proporre nuovi fatti candidati.
    Quando un componente propone un fatto canditato fornisce anche un valore di probabilità che corrisponde alla veridicità dell'informazione, corredato da motivi e dati aggiuntivi per meglio approfondire la causa.
    \item \textbf{Knowledge Integrator(KI)}: il componente che esamina i fatti candidati e promuove a credenze gli elementi più accreditati.
\end{itemize}

\noindent Dettagli maggiori sui componenti dell'architettura verranno forniti nella sezione di \nameref{impl}.

\centeredImage{img/architecture.png}{Architettura di NELL\cite{TowardAnArchitecture:online}}{0.7}

\noindent Non fanno parte dell'architettura del sistema, ma vengono utilizzati anche i \textbf{Data Resources} ovvero dei dati esterni che i Subsystem Components consultano per proporre nuovi fatti candidati. Per ogni iterazione che effettua il sistema, ogni componente termina la sua esecuzione usando la knowledge base di quel determinato periodo temporale, dopodiché il KI effettua le decisioni su quale fatto candidato promuovere a credenza.

\centeredImage{img/state.png}{Diagramma degli stati - Iterazioni}{0.8}

\noindent La knowledge base cresce iterazione dopo iterazione, e le nuove credenze generate vengono poi utilizzare dai componenti per effettuare un nuovo processo di training. Questo approccio è molto simile all'algoritmo di expectation–maximization (EM) in cui:
\begin{itemize}
    \item lo step \textit{E} crea la funzione per stimare il valore di verità per una grande quantità di "credenze candidate" della knowledge base;
    \item lo step \textit{M} effettua il training per massimizzare la funzione creata al passo precedente\cite{TowardAnArchitecture:online}.
\end{itemize}

\begin{info}[Algoritmo EM]
L'iterazione di EM alterna l'esecuzione di un passo chiamato expectation (E), che crea una funzione per il valore atteso della log-likelihood calcolata usando la stima dei parametri corrente, e un passo detto maximization (M), che calcola nuove stime dei parametri massimizzando la funzione di log-likelihood attesa trovata al passo appena descritto\cite{AlgoritmEM:online}.
\end{info}

\subsubsection{Principi di design}
Al fine di poter utilizzare l'approccio  appena descritto sono necessarie alcune accortezze sul design. Il fine è massimizzare l'efficacia del sistema:
\begin{itemize}
    \item ogni \textit{Subsystem component} deve commettere errori che non sono correlati tra loro. Questo implica l'utilizzo di un approccio molto diverso in ogni componente. Quando molti componenti commettono lo stesso errore (non correlato) la probabilità che tutti quanti hanno commesso lo stesso errore è il prodotto della probabilità dei singoli errori. Utilizzando metodi diversi, anche la modalità con cui vengono trovati gli errori cambia. In questo modo la probabilità di trovare degli effettivi errori cala drasticamente;
    \item sono necessari diversi punti di accesso da cui acquisire conoscenza. Per esempio un componente estrae fatti da risorse testuali, mentre un altro impara attraverso l'inferenza partendo da relazioni presenti della KB;
    \item è necessario un metodo per distinguere i fatti che hanno una alta affidabilità da quelli che risultano più incerti. Avere informazioni ulteriori sui motivi di tale classificazione aiuterebbe ulteriormente l'algoritmo a migliorarsi;
    \item è necessaria una rappresentazione standard per i fatti e le relazioni della KB. In questo modo risulterà anche più facile per il KI classificare i fatti candidati;
    \item è utile utilizzare metodi di apprendimento semi-supervisionato per sfruttare vincoli tra predicati già acquisiti. Per fornire più opportunità si organizzano in una tassonomia le categorie e le relazioni che sono state già classificate in modo corretto\cite{AlgoritmEM:online}.
\end{itemize}
\newpage