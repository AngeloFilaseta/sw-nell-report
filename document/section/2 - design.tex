\section{Design}
\subsection{Approcio ad alto livello}

I dati che sono stati forniti a NELL alla sua prima computazione sono stati i seguenti:
\begin{itemize}
    \item un'ontologia inziale, contenente circa qualche centinaio di categorie(tra cui \textit{persone}, \textit{team sportivi}, \textit{frutta}, \textit{emozioni}) e di relazioni(\textit{giocaNelTeam(atleta, team)}, \textit{suonaStrumento(musicista, strumentoMusicale)};
    \item circa 10 o 15 esempi di seed per ogni categoria o relazione;
    \item una collezione di circa 500 milioni di pagine web da cui estrapolare le informazioni;
    \begin{info}
        Anche se vengono fornite delle pagine di esempio, parte dell'algoritmo di NELL contiene anche indicazioni su come raggiungere autonomamente altre pagine web.
    \end{info}
\end{itemize}

\noindent Dal 2010 NELL continua la sua computazione, 24 ore al giorno, senza mai fermarsi, eseguendo a ripetizione due macro task:
\begin{enumerate}
    \item \textbf{estrazione di nuove istanze di categorie o relazioni}: in altre parole si cercano nuovi soggetti che possano essere legati ad una categoria già presente(es: "Barack Obama" è sia una \underline{persona} che un \underline{politico}) o due nuovi soggetti legati da una relazione già presente (es: "Taylor Swift" \underline{si è esibita} al "Levi's Stadium"). Questi fatti vengono quindi aggiunti alla knowledge base.
    \item \textbf{impara a leggere meglio di ieri}: NELL utilizza diversi metodi per estrarre informazioni dal web. Tutti gli algoritmi utilizzati subiscono un processo di training continuo utilizzando anche i nuovi dati trovati. Il metodo di apprendimento utilizzato da NELL è semi-supervisionato. Il suo successo è dovuto principalmente al continuo addestramento sui dati da parte di tutti gli algoritmi utilizzati per identificare fatti\cite{ReadtheWebOverview:online}.
\end{enumerate}

\newpage